{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T13:02:33.024826Z",
     "start_time": "2024-11-20T13:02:25.606291Z"
    }
   },
   "source": [
    "# the model is in ../models/Llama-3.2-1B-Instruct\n",
    "# load the llama model at try to do the chat\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from Classification.classification_bert import label_num_to_text\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model_path = \"../models/Llama-3.2-1B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path= model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\applications\\anaconda\\envs\\hku_nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (1): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (2): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (3): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (4): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (5): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (6): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (7): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (8): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (9): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (10): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (11): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (12): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (13): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (14): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "      (15): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:29:14.711305Z",
     "start_time": "2024-11-21T02:29:14.695359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "product = \"Furniture-Bookcases\"\n",
    "# read the json file at ../data_analysis/analysis_result_{}/analysis_result_{}.json\n",
    "with open(f\"../data_analysis/analysis_result_{product}/analysis_result_{product}.json\", \"r\") as f:\n",
    "    analysis_result = json.load(f)\n",
    "print(analysis_result.keys())\n",
    "\n",
    "# segment_distribution_text\n",
    "segment_distribution = analysis_result[\"segment_distribution\"]\n",
    "sorted_segment_distribution = sorted(segment_distribution.items(), key=lambda item: item[1][0], reverse=True)\n",
    "segment_distribution_text = \"The highest segment for {} is {}, which accounts for {:.2f}%.\".format(product, sorted_segment_distribution[0][0], sorted_segment_distribution[0][1][1]*100)\n",
    "print(segment_distribution_text)\n",
    "\n",
    "# segment_quantity_analysis\n",
    "segment_quantity_analysis = analysis_result[\"segment_quantity\"]\n",
    "sorted_segment_quantity_analysis = sorted(segment_quantity_analysis.items(), key=lambda item: item[1], reverse=True)\n",
    "segment_quantity_analysis_text = \"The highest segment quantity is {}, which bought average {} {} each time.\".format(sorted_segment_quantity_analysis[0][0], sorted_segment_quantity_analysis[0][1], product)\n",
    "print(segment_quantity_analysis_text)\n",
    "\n",
    "# segment_unit_price_analysis\n",
    "segment_unit_price_analysis = analysis_result[\"segment_unit_price\"]\n",
    "sorted_segment_unit_price_analysis = sorted(segment_unit_price_analysis.items(), key=lambda item: item[1], reverse=True)\n",
    "segment_unit_price_analysis_text = \"The highest segment unit price is {}, which paid {} for each {}.\".format(sorted_segment_unit_price_analysis[0][0], sorted_segment_unit_price_analysis[0][1], product)\n",
    "print(segment_unit_price_analysis_text)\n",
    "\n",
    "# segment_profit_analysis\n",
    "segment_profit_analysis = analysis_result[\"segment_profit\"]\n",
    "sorted_segment_profit_analysis = sorted(segment_profit_analysis.items(), key=lambda item: item[1], reverse=True)\n",
    "segment_profit_analysis_text = \"The highest segment profit is {}, which generated {} profit.\".format(sorted_segment_profit_analysis[0][0], sorted_segment_profit_analysis[0][1])\n",
    "print(segment_profit_analysis_text)\n",
    "\n",
    "# segment_discount_analysis\n",
    "segment_discount_analysis = analysis_result[\"segment_discount\"]\n",
    "sorted_segment_discount_analysis = sorted(segment_discount_analysis.items(), key=lambda item: item[1], reverse=True)\n",
    "segment_discount_analysis_text = \"The highest segment discount is {}, which got {} discount.\".format(sorted_segment_discount_analysis[0][0], sorted_segment_discount_analysis[0][1])\n",
    "print(segment_discount_analysis_text)\n",
    "\n",
    "# region_distribution\n",
    "region_distribution = analysis_result[\"region_distribution\"]\n",
    "sorted_region_distribution = sorted(region_distribution.items(), key=lambda item: item[1][1], reverse=True)\n",
    "region_distribution_text = \"The highest soling region for {} is {}, which accounts for {:.2f}%.\".format(product, sorted_region_distribution[0][0], sorted_region_distribution[0][1][1]*100)\n",
    "print(region_distribution_text)\n",
    "\n",
    "# shipping_mode_distribution\n",
    "shipping_mode_distribution = analysis_result[\"ship_mode_distribution\"]\n",
    "sorted_shipping_mode_distribution = sorted(shipping_mode_distribution.items(), key=lambda item: item[1][1], reverse=True)\n",
    "shipping_mode_distribution_text = \"The highest shipping mode for {} is {}, which accounts for {:.2f}%.\".format(product, sorted_shipping_mode_distribution[0][0], sorted_shipping_mode_distribution[0][1][1]*100)\n",
    "print(shipping_mode_distribution_text)\n",
    "\n",
    "# shipping_time_cost_analysis\n",
    "shipping_time_cost_analysis = analysis_result[\"ship_days_distribution\"]\n",
    "sorted_shipping_time_cost_analysis = sorted(shipping_time_cost_analysis.items(), key=lambda item: item[1][1], reverse=True)\n",
    "shipping_time_cost_analysis_text = \"The most common shipping time cost for {} is {} days, which accounts for {:.2f}%.\".format(product, sorted_shipping_time_cost_analysis[0][0], sorted_shipping_time_cost_analysis[0][1][1]*100)\n",
    "print(shipping_time_cost_analysis_text)"
   ],
   "id": "e25e6dd16278cdce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['segment_distribution', 'segment_quantity', 'segment_unit_price', 'segment_profit', 'segment_discount', 'region_distribution', 'ship_mode_distribution', 'ship_days_distribution', 'top_10_states', 'top_10_cities'])\n",
      "The highest segment for Furniture-Bookcases is Consumer, which accounts for 58.00%.\n",
      "The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time.\n",
      "The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases.\n",
      "The highest segment profit is Home Office, which generated 3.21 profit.\n",
      "The highest segment discount is Consumer, which got 0.22 discount.\n",
      "The highest soling region for Furniture-Bookcases is West, which accounts for 36.00%.\n",
      "The highest shipping mode for Furniture-Bookcases is Standard Class, which accounts for 54.00%.\n",
      "The most common shipping time cost for Furniture-Bookcases is 4 days, which accounts for 30.00%.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:24:27.572284Z",
     "start_time": "2024-11-21T02:24:27.551333Z"
    }
   },
   "cell_type": "code",
   "source": "analysis_result",
   "id": "6073f25ab8132589",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_distribution': {'Consumer': [130, 0.58],\n",
       "  'Corporate': [62, 0.28],\n",
       "  'Home Office': [33, 0.15]},\n",
       " 'segment_quantity': {'Consumer': 3.79,\n",
       "  'Corporate': 4.16,\n",
       "  'Home Office': 3.06},\n",
       " 'segment_unit_price': {'Consumer': 138.61,\n",
       "  'Corporate': 128.61,\n",
       "  'Home Office': 121.2},\n",
       " 'segment_profit': {'Consumer': -9.11, 'Corporate': 1.72, 'Home Office': 3.21},\n",
       " 'segment_discount': {'Consumer': 0.22,\n",
       "  'Corporate': 0.22,\n",
       "  'Home Office': 0.16},\n",
       " 'region_distribution': {'West': [80, 0.36],\n",
       "  'East': [67, 0.3],\n",
       "  'Central': [50, 0.22],\n",
       "  'South': [28, 0.12]},\n",
       " 'ship_mode_distribution': {'Standard Class': [122, 0.54],\n",
       "  'Second Class': [48, 0.21],\n",
       "  'First Class': [48, 0.21],\n",
       "  'Same Day': [7, 0.03]},\n",
       " 'ship_days_distribution': {'0': [7, 0.03],\n",
       "  '1': [12, 0.05],\n",
       "  '2': [41, 0.18],\n",
       "  '3': [21, 0.09],\n",
       "  '4': [67, 0.3],\n",
       "  '5': [44, 0.2],\n",
       "  '6': [21, 0.09],\n",
       "  '7': [12, 0.05]},\n",
       " 'top_10_states': {'California': [52, 0.23],\n",
       "  'New York': [31, 0.14],\n",
       "  'Texas': [27, 0.12],\n",
       "  'Washington': [10, 0.04],\n",
       "  'Pennsylvania': [10, 0.04],\n",
       "  'Illinois': [10, 0.04],\n",
       "  'Colorado': [9, 0.04],\n",
       "  'Florida': [8, 0.04],\n",
       "  'Ohio': [8, 0.04],\n",
       "  'Massachusetts': [6, 0.03]},\n",
       " 'top_10_cities': {'New York City': [28, 0.12],\n",
       "  'San Francisco': [16, 0.07],\n",
       "  'Los Angeles': [14, 0.06],\n",
       "  'Houston': [12, 0.05],\n",
       "  'Seattle': [10, 0.04],\n",
       "  'Philadelphia': [8, 0.04],\n",
       "  'Chicago': [6, 0.03],\n",
       "  'Dallas': [5, 0.02],\n",
       "  'Springfield': [4, 0.02],\n",
       "  'Columbus': [4, 0.02]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:37:47.742671Z",
     "start_time": "2024-11-21T02:37:47.730711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "known_facts = str({\n",
    "    \"product\": product,\n",
    "    \"most_segment_customers\": segment_distribution_text,\n",
    "    \"most_quantity_customers\": segment_quantity_analysis_text,\n",
    "    \"highest_unit_price_analysis\": segment_unit_price_analysis_text,\n",
    "    \"highest_profit_analysis\": segment_profit_analysis_text,\n",
    "    \"highest_discount_analysis\": segment_discount_analysis_text,\n",
    "    \"most_region_customers\": region_distribution_text,\n",
    "    \"most_shipping_mode_counts\": shipping_mode_distribution_text,\n",
    "    \"most_common_shipping_time_cost_counts\": shipping_time_cost_analysis_text\n",
    "})"
   ],
   "id": "4517249eb8ed7bd3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T13:53:18.049766Z",
     "start_time": "2024-11-20T13:53:09.252305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# IF using local LLAMA model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "input_text = \"For product {},known facts are: {},write a precise analysis less than 500 words\".format(product, known_facts)\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**input_ids, max_length=2048, do_sample=True, temperature=0.1)\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "id": "8a4106a1475296a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For product Furniture-Bookcases,known facts are: {'product': 'Furniture-Bookcases','most_segment_customers': 'The highest segment for Furniture-Bookcases is Consumer, which accounts for 58.00%.','most_quantity_customers': 'The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time.', 'highest_unit_price_analysis': 'The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases.', 'highest_profit_analysis': 'The highest segment profit is Home Office, which generated 3.21 profit.'},write a precise analysis less than 500 words.\n",
      "\n",
      "## Step 1: Identify the key facts about Furniture-Bookcases\n",
      "The given facts about Furniture-Bookcases include the product name, the most segment customers, the most quantity customers, the highest unit price analysis, and the highest profit analysis.\n",
      "\n",
      "## Step 2: Analyze the most segment customers\n",
      "The most segment customers for Furniture-Bookcases is Consumer, which accounts for 58.00%. This suggests that the majority of Furniture-Bookcases are being purchased by consumers.\n",
      "\n",
      "## Step 3: Analyze the most quantity customers\n",
      "The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time. This indicates that Corporate is the largest customer group for Furniture-Bookcases.\n",
      "\n",
      "## Step 4: Analyze the highest unit price analysis\n",
      "The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases. This suggests that consumers are willing to pay a premium for Furniture-Bookcases.\n",
      "\n",
      "## Step 5: Analyze the highest profit analysis\n",
      "The highest segment profit is Home Office, which generated 3.21 profit. This indicates that Home Office is the most profitable customer group for Furniture-Bookcases.\n",
      "\n",
      "## Step 6: Draw conclusions based on the analysis\n",
      "Based on the analysis, it appears that Furniture-Bookcases are primarily purchased by consumers, who are willing to pay a premium for them. Corporate is the largest customer group, and Furniture-Bookcases are the most profitable product for Home Office.\n",
      "\n",
      "## Step 7: Provide a precise analysis\n",
      "The analysis suggests that Furniture-Bookcases are a consumer-oriented product, with a high unit price and high profit margin. The majority of Furniture-Bookcases are purchased by Corporate, and the product is the most profitable for Home Office.\n",
      "\n",
      "The final answer is: $\\boxed{138.61}$\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:37:53.129927Z",
     "start_time": "2024-11-21T02:37:53.110970Z"
    }
   },
   "cell_type": "code",
   "source": "eval(known_facts)",
   "id": "ec86770966fde494",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Furniture-Bookcases',\n",
       " 'most_segment_customers': 'The highest segment for Furniture-Bookcases is Consumer, which accounts for 58.00%.',\n",
       " 'most_quantity_customers': 'The highest segment quantity is Corporate, which bought average 4.16 Furniture-Bookcases each time.',\n",
       " 'highest_unit_price_analysis': 'The highest segment unit price is Consumer, which paid 138.61 for each Furniture-Bookcases.',\n",
       " 'highest_profit_analysis': 'The highest segment profit is Home Office, which generated 3.21 profit.',\n",
       " 'highest_discount_analysis': 'The highest segment discount is Consumer, which got 0.22 discount.',\n",
       " 'most_region_customers': 'The highest soling region for Furniture-Bookcases is West, which accounts for 36.00%.',\n",
       " 'most_shipping_mode_counts': 'The highest shipping mode for Furniture-Bookcases is Standard Class, which accounts for 54.00%.',\n",
       " 'most_common_shipping_time_cost_counts': 'The most common shipping time cost for Furniture-Bookcases is 4 days, which accounts for 30.00%.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:40:10.878211Z",
     "start_time": "2024-11-21T02:39:59.798225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Another choice: using api from zhipu ai\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"06f59aab3f61a4e8ba0ef45b663fc204.ipiw6sxXKMQNoBY6\")  # 请填写您自己的APIKey\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",  # 请填写您要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"As a Sales Assistant to help the company, please analysis and generate sales suggestions and advise for the product {}, with less than 300 words.\".format(product)},\n",
    "        {\"role\": \"assistant\", \"content\": \"Of course, I can help you with that. Could you provide me with some information about the product?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Here are the facts: {}\".format(known_facts)},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ],
   "id": "64c27e28a55563ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionMessage(content=\"Based on the provided data, here are targeted sales suggestions for Furniture-Bookcases:\\n\\n**Customer Segmentation:**\\n1. **Consumer Focus:** Since Consumers account for 58% of sales and pay the highest unit price, tailor marketing efforts to highlight quality and design. Implement loyalty programs to encourage repeat purchases.\\n2. **Corporate Engagement:** Despite lower unit prices, Corporates buy in bulk (avg. 4.16 units). Offer volume discounts and bundled deals to increase order sizes.\\n\\n**Pricing Strategy:**\\n1. **Value Communication:** Emphasize the premium quality to justify the Consumer segment's high unit price. Use testimonials and case studies.\\n2. **Discount Optimization:** Balance discounts (Consumer avg. 0.22) to attract price-sensitive customers without eroding margins.\\n\\n**Regional Focus:**\\n1. **West Expansion:** Invest in targeted marketing and local partnerships in the West, which accounts for 36% of sales, to further penetrate this key market.\\n\\n**Shipping and Logistics:**\\n1. **Standard Class Efficiency:** Optimize Standard Class shipping (54% preference) for cost-effectiveness and reliability.\\n2. **Fast Turnaround:** Highlight the common 4-day shipping time in marketing to appeal to customers valuing quick delivery.\\n\\n**Profit Maximization:**\\n1. **Home Office Targeting:** Develop specialized campaigns for the Home Office segment, which generates the highest profit per unit, focusing on productivity and space-saving benefits.\\n\\nBy aligning these strategies with customer behavior and preferences, you can enhance sales and profitability for Furniture-Bookcases.\", role='assistant', tool_calls=None)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:46:27.870389Z",
     "start_time": "2024-11-21T02:46:27.860421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import mistune\n",
    "\n",
    "markdown_text = response.choices[0].message.content\n",
    "# markdown = mistune.create_markdown()\n",
    "# html = markdown(markdown_text)\n",
    "# print(html)\n",
    "\n",
    "from mistune import create_markdown, HTMLRenderer\n",
    "\n",
    "renderer = HTMLRenderer()\n",
    "markdown = create_markdown(renderer=renderer)\n",
    "html_output = markdown(markdown_text)\n",
    "print(html_output)\n",
    "\n",
    "# show the html output in a browser\n",
    "with open(\"output.html\", \"w\") as f:\n",
    "    f.write(html_output)"
   ],
   "id": "1da30f39bdc8bc75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Based on the provided data, here are targeted sales suggestions for Furniture-Bookcases:</p>\n",
      "<p><strong>Customer Segmentation:</strong></p>\n",
      "<ol>\n",
      "<li><strong>Consumer Focus:</strong> Since Consumers account for 58% of sales and pay the highest unit price, tailor marketing efforts to highlight quality and design. Implement loyalty programs to encourage repeat purchases.</li>\n",
      "<li><strong>Corporate Engagement:</strong> Despite lower unit prices, Corporates buy in bulk (avg. 4.16 units). Offer volume discounts and bundled deals to increase order sizes.</li>\n",
      "</ol>\n",
      "<p><strong>Pricing Strategy:</strong></p>\n",
      "<ol>\n",
      "<li><strong>Value Communication:</strong> Emphasize the premium quality to justify the Consumer segment's high unit price. Use testimonials and case studies.</li>\n",
      "<li><strong>Discount Optimization:</strong> Balance discounts (Consumer avg. 0.22) to attract price-sensitive customers without eroding margins.</li>\n",
      "</ol>\n",
      "<p><strong>Regional Focus:</strong></p>\n",
      "<ol>\n",
      "<li><strong>West Expansion:</strong> Invest in targeted marketing and local partnerships in the West, which accounts for 36% of sales, to further penetrate this key market.</li>\n",
      "</ol>\n",
      "<p><strong>Shipping and Logistics:</strong></p>\n",
      "<ol>\n",
      "<li><strong>Standard Class Efficiency:</strong> Optimize Standard Class shipping (54% preference) for cost-effectiveness and reliability.</li>\n",
      "<li><strong>Fast Turnaround:</strong> Highlight the common 4-day shipping time in marketing to appeal to customers valuing quick delivery.</li>\n",
      "</ol>\n",
      "<p><strong>Profit Maximization:</strong></p>\n",
      "<ol>\n",
      "<li><strong>Home Office Targeting:</strong> Develop specialized campaigns for the Home Office segment, which generates the highest profit per unit, focusing on productivity and space-saving benefits.</li>\n",
      "</ol>\n",
      "<p>By aligning these strategies with customer behavior and preferences, you can enhance sales and profitability for Furniture-Bookcases.</p>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T03:47:11.150228Z",
     "start_time": "2024-11-21T03:46:08.238124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now the gradio\n",
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import json\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "label_num_to_text = {0: ('Furniture', 'Bookcases'), 1: ('Furniture', 'Chairs'), 2: ('Furniture', 'Furnishings'), 3: ('Furniture', 'Tables'), 4: ('Office Supplies', 'Appliances'), 5: ('Office Supplies', 'Art'), 6: ('Office Supplies', 'Binders'), 7: ('Office Supplies', 'Envelopes'), 8: ('Office Supplies', 'Fasteners'), 9: ('Office Supplies', 'Labels'), 10: ('Office Supplies', 'Paper'), 11: ('Office Supplies', 'Storage'), 12: ('Office Supplies', 'Supplies'), 13: ('Technology', 'Accessories'), 14: ('Technology', 'Copiers'), 15: ('Technology', 'Machines'), 16: ('Technology', 'Phones')}\n",
    "# Load the BERT model and tokenizer\n",
    "model_path = '../Classification/results/checkpoint-1299'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=17, cache_dir=model_path)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Initialize ZhipuAI client\n",
    "client = ZhipuAI(api_key=\"06f59aab3f61a4e8ba0ef45b663fc204.ipiw6sxXKMQNoBY6\")\n",
    "\n",
    "# Function to classify commodity and generate sales suggestions\n",
    "def chatbot(commodity_name):\n",
    "    # Step 1: Classify the commodity's category using BERT\n",
    "    inputs = tokenizer(commodity_name, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "    preds = outputs.logits.argmax(-1).item()\n",
    "    category = label_num_to_text[preds][0]+\"-\"+label_num_to_text[preds][1]\n",
    "\n",
    "    # Step 2: Load the preprocessed analysis data for the category\n",
    "    analysis_file = f'../data_analysis/analysis_result_{category}/analysis_result_{category}.json'\n",
    "    with open(analysis_file, 'r') as f:\n",
    "        analysis_result = json.load(f)\n",
    "\n",
    "    # Extract known facts/features\n",
    "    known_facts = {\n",
    "        \"product\": category,\n",
    "        \"most_segment_customers\": analysis_result[\"segment_distribution\"],\n",
    "        \"most_quantity_customers\": analysis_result[\"segment_quantity\"],\n",
    "        \"highest_unit_price_analysis\": analysis_result[\"segment_unit_price\"],\n",
    "        \"highest_profit_analysis\": analysis_result[\"segment_profit\"],\n",
    "        \"highest_discount_analysis\": analysis_result[\"segment_discount\"],\n",
    "        \"most_region_customers\": analysis_result[\"region_distribution\"],\n",
    "        \"most_shipping_mode_counts\": analysis_result[\"ship_mode_distribution\"],\n",
    "        \"most_common_shipping_time_cost_counts\": analysis_result[\"ship_days_distribution\"]\n",
    "    }\n",
    "\n",
    "    # Step 3: Generate sales suggestions using ZhipuAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4-plus\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"As a Sales Assistant to help the company, please analyze and generate sales suggestions and advice for the product {category}, with less than 300 words.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Of course, I can help you with that. Could you provide me with some information about the product?\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here are the facts: {known_facts}\"}\n",
    "        ],\n",
    "    )\n",
    "    sales_suggestions = response.choices[0].message.content\n",
    "\n",
    "    return f\"The commodity '{commodity_name}' belongs to category '{category}'.\\n\\nSales Suggestions:\\n{sales_suggestions}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=chatbot,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Sales Assistant Chatbot\",\n",
    "    description=\"Ask the chatbot about a commodity and get sales suggestions.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch()"
   ],
   "id": "6cb0ae85bca50d6c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\applications\\anaconda\\envs\\hku_nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "D:\\applications\\anaconda\\envs\\hku_nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\HKU-MScAI-courses\\STAT7008 2\\2024\\Project\\Marketing_Recommonder_Chatbot\\Classification\\results\\checkpoint-1299\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
